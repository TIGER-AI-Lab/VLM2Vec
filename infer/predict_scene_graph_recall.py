 
import json
import torch
from PIL import Image
from tqdm import tqdm
import os
import sys
import warnings
from multiprocessing import Process, Queue, Manager
import math
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥srcæ¨¡å—
# è„šæœ¬ä½äº embedding/infer/ ç›®å½•ä¸‹ï¼Œéœ€è¦å‘ä¸Šä¸¤çº§æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(script_dir))
if project_root not in sys.path:
    sys.path.insert(0, project_root)


def check_flash_attention_support():

    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
        if not torch.cuda.is_available():
            return False, "CUDAä¸å¯ç”¨"
        
        # è·å–GPUè®¡ç®—èƒ½åŠ›
        device_capability = torch.cuda.get_device_capability()
        major, minor = device_capability
        compute_capability = major * 10 + minor
        
        # Flash Attention 2éœ€è¦è®¡ç®—èƒ½åŠ› >= 8.0 (AmpereåŠä»¥ä¸Šæ¶æ„)
        # Flash Attention 1éœ€è¦è®¡ç®—èƒ½åŠ› >= 7.5 (TuringåŠä»¥ä¸Šæ¶æ„)
        if compute_capability >= 80:
            # å°è¯•å¯¼å…¥flash_attn
            try:
                import flash_attn
                return True, f"æ”¯æŒFlash Attention (GPUè®¡ç®—èƒ½åŠ›: {major}.{minor})"
            except ImportError:
                return False, f"GPUæ”¯æŒä½†æœªå®‰è£…flash_attnåŒ… (è®¡ç®—èƒ½åŠ›: {major}.{minor})"
        else:
            return False, f"GPUè®¡ç®—èƒ½åŠ›ä¸è¶³ (å½“å‰: {major}.{minor}, éœ€è¦: >= 8.0)"
            
    except Exception as e:
        return False, f"æ£€æµ‹å¤±è´¥: {str(e)}"


def configure_attention_backend():

    is_supported, message = check_flash_attention_support()
    
    print("\n" + "="*80)
    print("æ³¨æ„åŠ›æœºåˆ¶é…ç½®")
    print("="*80)
    
    if is_supported:
        print(f"âœ… {message}")
        print("   ä½¿ç”¨: Flash Attention (æœ€å¿«)")
        os.environ["ATTN_IMPLEMENTATION"] = "flash_attention_2"
        # åŒæ—¶è®¾ç½®transformersä½¿ç”¨çš„ç¯å¢ƒå˜é‡
        os.environ["USE_FLASH_ATTENTION"] = "1"
        return "flash_attn"
    else:
        print(f"âš ï¸  {message}")
        
        # æ£€æŸ¥PyTorchç‰ˆæœ¬æ˜¯å¦æ”¯æŒSDPA
        pytorch_version = torch.__version__
        major, minor = map(int, pytorch_version.split('.')[:2])
        
        if major >= 2:  # PyTorch 2.0+æ”¯æŒSDPA
            print("   é™çº§ä½¿ç”¨: Scaled Dot Product Attention (SDPA)")
            print("   æ€§èƒ½: ä¸­ç­‰ï¼Œä½†æ¯”eageræ¨¡å¼å¿«")
            os.environ["ATTN_IMPLEMENTATION"] = "sdpa"
            os.environ["USE_FLASH_ATTENTION"] = "0"
            return "sdpa"
        else:
            print("   é™çº§ä½¿ç”¨: Eager Attention (æ ‡å‡†å®ç°)")
            print("   æ€§èƒ½: è¾ƒæ…¢ï¼Œä½†å…¼å®¹æ€§æœ€å¥½")
            os.environ["ATTN_IMPLEMENTATION"] = "eager"
            os.environ["USE_FLASH_ATTENTION"] = "0"
            return "eager"
    
    print("="*80 + "\n")


_attn_type = configure_attention_backend()

# ç°åœ¨æ‰å¯¼å…¥VLM2Vecæ¨¡å—
from src.model.model import MMEBModel
from src.arguments import ModelArguments, DataArguments
from src.model.processor import load_processor, QWEN2_VL, VLM_IMAGE_TOKENS


INPUT_FILE = "/public/home/xiaojw2025/Workspace/RAHP/DATASET/VG150/test_2000_images.json"
OUTPUT_FILE = "/public/home/xiaojw2025/Workspace/VLM2Vec/predict/recall_results_2000_train_5k_ratio.json"

# é»˜è®¤ä½¿ç”¨çš„GPUæ•°é‡ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨GPUï¼‰
# ä¹Ÿå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•° --num_gpus æˆ–ç¯å¢ƒå˜é‡ NUM_GPUS æŒ‡å®š
NUM_GPUS = None  # è®¾ç½®ä¸º None ä½¿ç”¨æ‰€æœ‰GPUï¼Œæˆ–è®¾ç½®ä¸ºå…·ä½“æ•°å­—å¦‚ 2 è¡¨ç¤ºåªä½¿ç”¨2ä¸ªGPU

# 50ä¸ªè°“è¯åˆ—è¡¨
PREDICATES = [
    "above", "across", "against", "along", "and", "at", "attached to", "behind",
    "belonging to", "between", "carrying", "covered in", "covering", "eating",
    "flying in", "for", "from", "growing on", "hanging from", "has", "holding",
    "in", "in front of", "laying on", "looking at", "lying on", "made of",
    "mounted on", "near", "of", "on", "on back of", "over", "painted on",
    "parked on", "part of", "playing", "riding", "says", "sitting on",
    "standing on", "to", "under", "using", "walking in", "walking on",
    "watching", "wearing", "wears", "with","no relation"
]


def format_bbox_as_special_token(bbox, normalize=True, original_width=1024, original_height=1024):
    """å°†è¾¹ç•Œæ¡†è½¬æ¢ä¸ºQwen2-VLçš„special tokenæ ¼å¼"""
    if isinstance(bbox, (list, tuple)) and len(bbox) == 4:
        x1, y1, x2, y2 = bbox
        
        if normalize:
            x1_norm = int((x1 / original_width) * 1000)
            y1_norm = int((y1 / original_height) * 1000)
            x2_norm = int((x2 / original_width) * 1000)
            y2_norm = int((y2 / original_height) * 1000)
            
            x1_norm = max(0, min(x1_norm, 999))
            y1_norm = max(0, min(y1_norm, 999))
            x2_norm = max(0, min(x2_norm, 999))
            y2_norm = max(0, min(y2_norm, 999))
            
            x1_norm, x2_norm = min(x1_norm, x2_norm), max(x1_norm, x2_norm)
            y1_norm, y2_norm = min(y1_norm, y2_norm), max(y1_norm, y2_norm)
            
            if x1_norm == x2_norm:
                x2_norm = min(x1_norm + 1, 999)
            if y1_norm == y2_norm:
                y2_norm = min(y1_norm + 1, 999)
            
            return f"<|box_start|>({x1_norm}, {y1_norm}), ({x2_norm}, {y2_norm})<|box_end|>"
    return ""

def format_object_with_ref(object_label):
    return f"<|object_ref_start|>{object_label}<|object_ref_end|>"


def precompute_predicate_vectors(model, processor, predicates, device='cuda'):
    """
    é¢„è®¡ç®—æ‰€æœ‰è°“è¯çš„å‘é‡è¡¨ç¤ºï¼ˆåªéœ€è¦è®¡ç®—ä¸€æ¬¡ï¼‰
    
    Args:
        model: VLM2Vecæ¨¡å‹
        processor: æ–‡æœ¬å¤„ç†å™¨
        predicates: è°“è¯åˆ—è¡¨
        device: è®¾å¤‡åç§°ï¼Œå¦‚ 'cuda:0'
    
    Returns:
        predicate_vectors: [num_predicates, hidden_dim] çš„tensor
    """
    print(f"ğŸ”§ é¢„è®¡ç®—è°“è¯å‘é‡ (è®¾å¤‡: {device})...")
    predicate_vectors = []
    
    for predicate in tqdm(predicates, desc=f"ç¼–ç è°“è¯ [{device}]"):
        predicate_text = f"The subject is {predicate} the object."
        inputs = processor(text=predicate_text, images=None, return_tensors="pt")
        inputs = {key: value.to(device) for key, value in inputs.items()}
        
        with torch.no_grad():
            tgt_output = model(tgt=inputs)["tgt_reps"]
            predicate_vectors.append(tgt_output)
    
    # å †å æˆä¸€ä¸ªtensor: [num_predicates, hidden_dim]
    predicate_vectors = torch.cat(predicate_vectors, dim=0)
    print(f"âœ… è°“è¯å‘é‡é¢„è®¡ç®—å®Œæˆï¼Œshape: {predicate_vectors.shape}")
    
    return predicate_vectors


def predict_relation(model, processor, image_path, subject_obj, object_obj, 
                     original_width, original_height, predicate_vectors=None, device='cuda'):
    """
    é¢„æµ‹å…³ç³»ï¼Œä½¿ç”¨é¢„è®¡ç®—çš„è°“è¯å‘é‡
    
    Args:
        predicate_vectors: é¢„è®¡ç®—çš„è°“è¯å‘é‡ [num_predicates, hidden_dim]ï¼Œå¦‚æœä¸ºNoneåˆ™å®æ—¶è®¡ç®—
        device: è®¾å¤‡åç§°ï¼Œå¦‚ 'cuda:0'
    """
    # æ„å»ºsubjectå’Œobjectçš„ç‰¹æ®Štoken
    subj_bbox_token = format_bbox_as_special_token(
        subject_obj['bbox'], True, original_width, original_height
    )
    obj_bbox_token = format_bbox_as_special_token(
        object_obj['bbox'], True, original_width, original_height
    )
    subj_ref = format_object_with_ref(subject_obj['class_name'])
    obj_ref = format_object_with_ref(object_obj['class_name'])
    
    query_text = f"{VLM_IMAGE_TOKENS[QWEN2_VL]} In the given image, the subject {subj_ref} is located at {subj_bbox_token},the object{obj_ref} is located at {obj_bbox_token}.Please describe the predicate relationship between the subject and the object but if there is no relation return 'no relation'."
    
    inputs = processor(
        text=query_text,
        images=Image.open(image_path),
        return_tensors="pt"
    )
    inputs = {key: value.to(device) for key, value in inputs.items()}
    inputs['pixel_values'] = inputs['pixel_values'].unsqueeze(0)
    inputs['image_grid_thw'] = inputs['image_grid_thw'].unsqueeze(0)
    
    try:
        with torch.no_grad():
            qry_output = model(qry=inputs)["qry_reps"]
    except RuntimeError as e:
        # æ•è·Flash Attentionè¿è¡Œæ—¶é”™è¯¯
        if "FlashAttention only supports Ampere" in str(e):
            raise RuntimeError(
                "æ£€æµ‹åˆ°Flash Attentionè¿è¡Œæ—¶é”™è¯¯ï¼šæ‚¨çš„GPUä¸æ”¯æŒFlash Attentionã€‚\n"
                "è¯·åœ¨è¿è¡Œè„šæœ¬å‰è®¾ç½®ç¯å¢ƒå˜é‡: export USE_FLASH_ATTENTION=0\n"
                f"åŸå§‹é”™è¯¯: {str(e)}"
            )
        else:
            raise
    
    # è®¡ç®—ä¸æ‰€æœ‰è°“è¯çš„ç›¸ä¼¼åº¦
    predicate_scores = []
    
    if predicate_vectors is not None:
        # ä½¿ç”¨é¢„è®¡ç®—çš„è°“è¯å‘é‡ï¼ˆé€ä¸ªè®¡ç®—ç›¸ä¼¼åº¦ï¼‰
        with torch.no_grad():
            # qry_output: [1, hidden_dim]
            # predicate_vectors: [num_predicates, hidden_dim]
            for i, predicate in enumerate(PREDICATES):
                similarity = model.compute_similarity(
                    qry_output, 
                    predicate_vectors[i:i+1]  # å–å•ä¸ªè°“è¯å‘é‡ [1, hidden_dim]
                )
                predicate_scores.append({
                    'predicate': predicate,
                    'similarity': similarity.item()
                })
    else:
        # åŸå§‹æ–¹æ³•ï¼šé€ä¸ªç¼–ç è°“è¯ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        for predicate in PREDICATES:
            inputs = processor(text=predicate, images=None, return_tensors="pt")
            inputs = {key: value.to(device) for key, value in inputs.items()}
            
            with torch.no_grad():
                tgt_output = model(tgt=inputs)["tgt_reps"]
                similarity = model.compute_similarity(qry_output, tgt_output)
            
            predicate_scores.append({
                'predicate': predicate,
                'similarity': similarity.item()
            })
    
    return predicate_scores


def calculate_recall_at_k_per_image(image_candidate_predictions, k=50):
    """
    è®¡ç®—å•å¼ å›¾ç‰‡çš„recall@k
    ç°åœ¨æ”¯æŒæ‰€æœ‰ç‰©ä½“ä¸¤ä¸¤é…å¯¹çš„é¢„æµ‹ç»“æœ
    
    ä¿®æ”¹ï¼šå…ˆè¿‡æ»¤no relationï¼Œå†å–top-kï¼ˆä¸evaluate_results.pyå¯¹é½ï¼‰
    """
    # è·å–è¯¥å›¾ç‰‡ä¸­æ‰€æœ‰GTå…³ç³»ï¼ˆåªç»Ÿè®¡relation_idx >= 0çš„ï¼Œæ’é™¤-1ï¼‰
    gt_relations = set()
    for pred in image_candidate_predictions:
        if pred['has_gt'] and pred['relation_idx'] >= 0:
            gt_relations.add(pred['relation_idx'])
    
    # ç¬¬ä¸€æ­¥ï¼šè¿‡æ»¤æ‰no relationçš„é¢„æµ‹ï¼ˆä»æ‰€æœ‰å€™é€‰ä¸­ï¼‰
    non_bg_candidates = []
    for pred in image_candidate_predictions:
        if pred.get('predicted_predicate') != 'no relation':
            non_bg_candidates.append(pred)
    
    # ç¬¬äºŒæ­¥ï¼šæŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå–top-k
    predictions_sorted = sorted(non_bg_candidates, key=lambda x: x['similarity'], reverse=True)
    actual_k = min(k, len(predictions_sorted))  # å¦‚æœå€™é€‰æ•°ä¸è¶³kï¼Œå–å…¨éƒ¨
    top_k_predictions = predictions_sorted[:actual_k]
    
    # ç¬¬ä¸‰æ­¥ï¼šåœ¨top-kä¸­ï¼Œåªå¯¹GTå…³ç³»å¯¹è¿›è¡Œè¯„ä¼°ï¼Œç»Ÿè®¡å¬å›çš„å…³ç³»ï¼ˆå»é‡ï¼‰
    recalled_relations = set()
    for pred in top_k_predictions:
        # åªç»Ÿè®¡GTå…³ç³»å¯¹ä¸­é¢„æµ‹æ­£ç¡®çš„
        if pred['relation_idx'] in gt_relations and pred['is_correct']:
            recalled_relations.add(pred['relation_idx'])
    
    # æ€»GTå…³ç³»æ•°
    total_gt_relations = len(gt_relations)
    
    recall = len(recalled_relations) / total_gt_relations if total_gt_relations > 0 else 0.0
    
    # ç»Ÿè®¡æ€»é¢„æµ‹å¯¹æ•°ï¼ˆåŒ…æ‹¬æ— GTçš„é…å¯¹ï¼‰
    total_pairs = len(set((pred['subject'], pred['object']) for pred in image_candidate_predictions))
    gt_pairs = len(set((pred['subject'], pred['object']) for pred in image_candidate_predictions if pred['has_gt']))
    
    return {
        'recall@k': recall,
        'k': k,
        'actual_k': actual_k,  # å®é™…å–çš„æ•°é‡ï¼ˆè¿‡æ»¤no relationåï¼‰
        'recalled_relations': len(recalled_relations),
        'total_gt_relations': total_gt_relations,
        'total_candidates': len(image_candidate_predictions),
        'top_k_candidates': len(top_k_predictions),
        'total_pairs': total_pairs,  # æ€»é¢„æµ‹å¯¹æ•°
        'gt_pairs': gt_pairs,  # æœ‰GTçš„é…å¯¹å¯¹æ•°
        'non_gt_pairs': total_pairs - gt_pairs  # æ— GTçš„é…å¯¹å¯¹æ•°
    }


def calculate_mean_recall_per_predicate(per_image_candidates, predicates, k=50):
    """
    è®¡ç®—æ¯ä¸ªè°“è¯ç±»åˆ«çš„mean recall@50
    
    Args:
        per_image_candidates: dict, keyä¸ºimage_id, valueä¸ºè¯¥å›¾ç‰‡çš„æ‰€æœ‰å€™é€‰é¢„æµ‹åˆ—è¡¨
        predicates: æ‰€æœ‰è°“è¯ç±»åˆ«åˆ—è¡¨
        k: top-k
    
    Returns:
        dict: æ¯ä¸ªè°“è¯çš„recallå’Œæ•´ä½“mean recall
    
    ä¿®æ”¹ï¼šå…ˆè¿‡æ»¤no relationï¼Œå†å–top-kï¼ˆä¸evaluate_results.pyå¯¹é½ï¼‰
    """
    # åˆå§‹åŒ–æ¯ä¸ªè°“è¯çš„ç»Ÿè®¡
    predicate_stats = {pred: {'hit': 0, 'total': 0} for pred in predicates}
    
    for image_id, candidates in per_image_candidates.items():
        # è·å–è¯¥å›¾ç‰‡ä¸­æ‰€æœ‰GTå…³ç³»ï¼ˆåªç»Ÿè®¡relation_idx >= 0çš„ï¼Œæ’é™¤-1ï¼‰
        gt_relations = set()
        for cand in candidates:
            if cand['relation_idx'] >= 0:
                gt_relations.add(cand['relation_idx'])
        
        # ç¬¬ä¸€æ­¥ï¼šè¿‡æ»¤æ‰no relationçš„é¢„æµ‹ï¼ˆä»æ‰€æœ‰å€™é€‰ä¸­ï¼‰
        non_bg_candidates = []
        for cand in candidates:
            if cand.get('predicted_predicate') != 'no relation':
                non_bg_candidates.append(cand)
        
        # ç¬¬äºŒæ­¥ï¼šæŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå–top-k
        predictions_sorted = sorted(non_bg_candidates, key=lambda x: x['similarity'], reverse=True)
        actual_k = min(k, len(predictions_sorted))
        top_k_predictions = predictions_sorted[:actual_k]
        
        # ç»Ÿè®¡è¯¥å›¾ç‰‡ä¸­æ¯ä¸ªè°“è¯ç±»åˆ«çš„GT
        gt_predicates_in_image = {}
        recalled_predicates_in_image = {}
        
        for cand in candidates:
            if not cand['has_gt'] or cand['relation_idx'] == -1:
                continue  # è·³è¿‡æ²¡æœ‰GTçš„é…å¯¹
                
            gt_pred = cand['gt_predicate']
            relation_idx = cand['relation_idx']
            
            # ç»Ÿè®¡GTï¼ˆæ¯ä¸ªå…³ç³»åªç®—ä¸€æ¬¡ï¼‰
            if relation_idx not in gt_predicates_in_image:
                gt_predicates_in_image[relation_idx] = gt_pred
                predicate_stats[gt_pred]['total'] += 1
        
        # ç¬¬ä¸‰æ­¥ï¼šåœ¨top-kä¸­ï¼Œåªå¯¹GTå…³ç³»å¯¹è¿›è¡Œè¯„ä¼°ï¼Œç»Ÿè®¡å¬å›çš„è°“è¯
        for cand in top_k_predictions:
            # åªç»Ÿè®¡GTå…³ç³»å¯¹ä¸­é¢„æµ‹æ­£ç¡®çš„
            if cand['relation_idx'] in gt_relations and cand['is_correct']:
                relation_idx = cand['relation_idx']
                gt_pred = cand['gt_predicate']
                
                # æ¯ä¸ªå…³ç³»åªç®—ä¸€æ¬¡å¬å›
                if relation_idx not in recalled_predicates_in_image:
                    recalled_predicates_in_image[relation_idx] = gt_pred
                    predicate_stats[gt_pred]['hit'] += 1
    
    # è®¡ç®—æ¯ä¸ªè°“è¯çš„recall
    per_predicate_recall = {}
    valid_predicates = []
    
    for pred in predicates:
        total = predicate_stats[pred]['total']
        hit = predicate_stats[pred]['hit']
        
        if total > 0:
            recall = hit / total
            per_predicate_recall[pred] = {
                'recall': recall,
                'hit': hit,
                'total': total
            }
            valid_predicates.append(recall)
        else:
            per_predicate_recall[pred] = {
                'recall': 0.0,
                'hit': 0,
                'total': 0
            }
    
    # è®¡ç®—mean recallï¼ˆåªå¯¹æœ‰GTçš„ç±»åˆ«è®¡ç®—ï¼‰
    mean_recall = sum(valid_predicates) / len(valid_predicates) if valid_predicates else 0.0
    
    return {
        'mean_recall@k': mean_recall,
        'k': k,
        'per_predicate_recall': per_predicate_recall,
        'num_valid_predicates': len(valid_predicates),
        'total_predicates': len(predicates)
    }


def calculate_average_recall_at_k(per_image_candidates, k=50):

    per_image_results = []
    total_recall = 0.0
    valid_images = 0
    
    for image_id, candidates in per_image_candidates.items():
        # è®¡ç®—è¯¥å›¾ç‰‡çš„recall
        img_result = calculate_recall_at_k_per_image(candidates, k)
        img_result['image_id'] = image_id
        per_image_results.append(img_result)
        
        total_recall += img_result['recall@k']
        valid_images += 1
    
    # è®¡ç®—å¹³å‡recall
    avg_recall = total_recall / valid_images if valid_images > 0 else 0.0
    
    # ç»Ÿè®¡æ€»ä½“ä¿¡æ¯
    total_gt_relations = sum(r['total_gt_relations'] for r in per_image_results)
    total_recalled_relations = sum(r['recalled_relations'] for r in per_image_results)
    
    # ç»Ÿè®¡å€™é€‰æ•°ä¸è¶³kçš„å›¾ç‰‡æ•°é‡
    images_with_insufficient_candidates = sum(1 for r in per_image_results if r['actual_k'] < k)
    
    return {
        'avg_recall@k': avg_recall,
        'k': k,
        'total_images': valid_images,
        'total_gt_relations': total_gt_relations,
        'total_recalled_relations': total_recalled_relations,
        'images_with_insufficient_candidates': images_with_insufficient_candidates,
        'per_image_results': per_image_results
    }


def process_data_shard(gpu_id, data_shard, model_args, data_args, predicate_vectors_dict, result_queue, progress_queue):
    """
    åœ¨æŒ‡å®šGPUä¸Šå¤„ç†æ•°æ®åˆ†ç‰‡
    
    Args:
        gpu_id: GPU ID (0, 1, 2, ...)
        data_shard: è¯¥GPUè¦å¤„ç†çš„æ•°æ®åˆ†ç‰‡ï¼ˆå›¾ç‰‡åˆ—è¡¨ï¼‰
        model_args: æ¨¡å‹å‚æ•°
        data_args: æ•°æ®å‚æ•°
        predicate_vectors_dict: å…±äº«çš„è°“è¯å‘é‡å­—å…¸ï¼ˆé€šè¿‡Manageråˆ›å»ºï¼‰
        result_queue: ç»“æœé˜Ÿåˆ—
        progress_queue: è¿›åº¦é˜Ÿåˆ—
    """
    device = f'cuda:{gpu_id}'
    torch.cuda.set_device(gpu_id)
    
    try:
        # åŠ è½½å¤„ç†å™¨å’Œæ¨¡å‹ï¼ˆæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹åŠ è½½ï¼‰
        processor = load_processor(model_args, data_args)
        
        # å°è¯•åŠ è½½æ¨¡å‹
        try:
            model = MMEBModel.load(model_args)
            model = model.to(device, dtype=torch.bfloat16)
            model.eval()
        except Exception as e:
            error_msg = str(e)
            if ("flash" in error_msg.lower() or 
                "ampere" in error_msg.lower() or 
                "attention" in error_msg.lower() and "support" in error_msg.lower()):
                # å¼ºåˆ¶ä½¿ç”¨eageræ¨¡å¼
                os.environ["ATTN_IMPLEMENTATION"] = "eager"
                os.environ["USE_FLASH_ATTENTION"] = "0"
                
                import importlib
                import src.model.model
                importlib.reload(src.model.model)
                from src.model.model import MMEBModel as MMEBModelReloaded
                
                processor = load_processor(model_args, data_args)
                model = MMEBModelReloaded.load(model_args)
                model = model.to(device, dtype=torch.bfloat16)
                model.eval()
            else:
                raise
        
        # è·å–æˆ–é¢„è®¡ç®—è°“è¯å‘é‡
        if gpu_id not in predicate_vectors_dict:
            # å¦‚æœè¯¥GPUè¿˜æ²¡æœ‰è°“è¯å‘é‡ï¼Œåˆ™é¢„è®¡ç®—
            predicate_vectors = precompute_predicate_vectors(model, processor, PREDICATES, device=device)
            predicate_vectors_dict[gpu_id] = predicate_vectors.cpu()  # ä¿å­˜åˆ°CPUä»¥ä¾¿å…±äº«
        else:
            # ä½¿ç”¨å…±äº«çš„è°“è¯å‘é‡ï¼ˆéœ€è¦ç§»å›GPUï¼‰
            predicate_vectors = predicate_vectors_dict[gpu_id].to(device)
        
        # å¤„ç†è¯¥GPUçš„æ•°æ®åˆ†ç‰‡
        per_image_candidates = {}
        all_relations_info = []
        processed_images = 0
        for img_idx, img_data in enumerate(data_shard):
            image_id = img_data['image_id']
            image_path = img_data['image_path']
            objects = img_data['objects']
            relations = img_data['relations']
            
            # æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_path):
                progress_queue.put((gpu_id, f"âš ï¸  GPU{gpu_id}: å›¾åƒä¸å­˜åœ¨ {image_path}"))
                continue
            
            # è·å–å›¾åƒå°ºå¯¸
            with Image.open(image_path) as img:
                original_width, original_height = img.size
            
            # åˆ›å»ºç‰©ä½“IDåˆ°ç‰©ä½“ä¿¡æ¯çš„æ˜ å°„
            obj_dict = {obj['id']: obj for obj in objects}
            
            # åˆå§‹åŒ–è¯¥å›¾ç‰‡çš„å€™é€‰åˆ—è¡¨
            image_candidates = []
            image_relation_idx = 0
            
            # åˆ›å»ºGTå…³ç³»æ˜ å°„
            gt_relations_map = {}
            for relation in relations:
                subject_id = relation['subject_id']
                object_id = relation['object_id']
                gt_predicate = relation['predicate']
                if (subject_id, object_id) not in gt_relations_map:
                    gt_relations_map[(subject_id, object_id)] = []
                gt_relations_map[(subject_id, object_id)].append(gt_predicate)
            
            # å¯¹æ‰€æœ‰ç‰©ä½“è¿›è¡Œä¸¤ä¸¤é…å¯¹é¢„æµ‹
            object_ids = list(obj_dict.keys())
            for i, subject_id in enumerate(object_ids):
                for j, object_id in enumerate(object_ids):
                    if i == j:
                        continue
                    
                    subject_obj = obj_dict[subject_id]
                    object_obj = obj_dict[object_id]
                    
                    # é¢„æµ‹å…³ç³»
                    predicate_scores = predict_relation(
                        model, processor, image_path,
                        subject_obj, object_obj,
                        original_width, original_height,
                        predicate_vectors=predicate_vectors,
                        device=device
                    )
                    
                    # åˆ¤æ–­è¯¥é…å¯¹æ˜¯å¦æœ‰GTå…³ç³»
                    has_gt = (subject_id, object_id) in gt_relations_map
                    gt_predicates = gt_relations_map.get((subject_id, object_id), [])
                    
                    # è®°å½•å…³ç³»ä¿¡æ¯
                    if has_gt:
                        for gt_predicate in gt_predicates:
                            all_relations_info.append({
                                'relation_idx': -1,  # å°†åœ¨ä¸»è¿›ç¨‹é‡æ–°åˆ†é…
                                'image_id': image_id,
                                'image_relation_idx': image_relation_idx,
                                'subject': subject_obj['class_name'],
                                'object': object_obj['class_name'],
                                'gt_predicate': gt_predicate
                            })
                            image_relation_idx += 1
                    
                    # å°†è¯¥é…å¯¹çš„50ä¸ªè°“è¯å€™é€‰åŠ å…¥å€™é€‰æ± 
                    # è®¡ç®—è¯¥é…å¯¹å¯¹åº”çš„å…³ç³»ç´¢å¼•èµ·å§‹å€¼
                    relation_idx_start = image_relation_idx - len(gt_predicates) if has_gt else -1
                    
                    for pred_score in predicate_scores:
                        is_correct = False
                        if has_gt and pred_score['predicate'] in gt_predicates:
                            is_correct = True
                        
                        # å¦‚æœé¢„æµ‹æ­£ç¡®ï¼Œæ‰¾åˆ°å¯¹åº”çš„å…³ç³»ç´¢å¼•
                        relation_idx = -1
                        if is_correct and has_gt:
                            # æ‰¾åˆ°è¯¥è°“è¯åœ¨gt_predicatesä¸­çš„ä½ç½®
                            for idx, gt_pred in enumerate(gt_predicates):
                                if gt_pred == pred_score['predicate']:
                                    relation_idx = relation_idx_start + idx
                                    break
                        
                        image_candidates.append({
                            'relation_idx': relation_idx,
                            'global_relation_idx': -1,  # å°†åœ¨ä¸»è¿›ç¨‹é‡æ–°åˆ†é…
                            'image_id': image_id,
                            'subject': subject_obj['class_name'],
                            'object': object_obj['class_name'],
                            'gt_predicate': gt_predicates[0] if gt_predicates else None,
                            'gt_predicates': gt_predicates,
                            'predicted_predicate': pred_score['predicate'],
                            'similarity': pred_score['similarity'],
                            'is_correct': is_correct,
                            'has_gt': has_gt
                        })
            
            per_image_candidates[image_id] = image_candidates
            processed_images += 1
            
            # æ›´æ–°è¿›åº¦
            if (img_idx + 1) % 10 == 0:
                progress_queue.put((gpu_id, f"GPU{gpu_id}: å·²å¤„ç† {img_idx + 1}/{len(data_shard)} å¼ å›¾ç‰‡"))
        
        # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
        result_queue.put({
            'gpu_id': gpu_id,
            'per_image_candidates': per_image_candidates,
            'all_relations_info': all_relations_info
        })
        
        progress_queue.put((gpu_id, f"âœ… GPU{gpu_id}: å®Œæˆå¤„ç† {processed_images} å¼ å›¾ç‰‡"))
        
    except Exception as e:
        import traceback
        error_msg = f"GPU{gpu_id}å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        result_queue.put({
            'gpu_id': gpu_id,
            'error': error_msg
        })
        progress_queue.put((gpu_id, f"âŒ {error_msg}"))



def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='åœºæ™¯å›¾å…³ç³»é¢„æµ‹ä¸Per-Image Recall@50è®¡ç®—')
    parser.add_argument('--num_gpus', type=int, default=None,
                        help='æŒ‡å®šä½¿ç”¨çš„GPUæ•°é‡ï¼ˆé»˜è®¤ï¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨GPUï¼Œæˆ–ä»NUM_GPUSç¯å¢ƒå˜é‡/é…ç½®å˜é‡è¯»å–ï¼‰')
    parser.add_argument('--input_file', type=str, default=None,
                        help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„INPUT_FILEï¼‰')
    parser.add_argument('--output_file', type=str, default=None,
                        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„OUTPUT_FILEï¼‰')
    args = parser.parse_args()
    
    # ç¡®å®šä½¿ç”¨çš„GPUæ•°é‡ï¼ˆä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é…ç½®å˜é‡ > æ‰€æœ‰GPUï¼‰
    num_gpus_to_use = args.num_gpus
    if num_gpus_to_use is None:
        num_gpus_to_use = os.environ.get('NUM_GPUS')
        if num_gpus_to_use is not None:
            num_gpus_to_use = int(num_gpus_to_use)
        else:
            num_gpus_to_use = NUM_GPUS
    
    # ç¡®å®šè¾“å…¥è¾“å‡ºæ–‡ä»¶
    input_file = args.input_file if args.input_file else INPUT_FILE
    output_file = args.output_file if args.output_file else OUTPUT_FILE
    
    print("="*80)
    print("åœºæ™¯å›¾å…³ç³»é¢„æµ‹ä¸Per-Image Recall@50è®¡ç®—")
    print("="*80)

    # æ£€æµ‹å¯ç”¨GPUæ•°é‡
    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯: æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡")
        return
    
    total_gpus = torch.cuda.device_count()
    print(f"\nğŸ” æ£€æµ‹åˆ° {total_gpus} ä¸ªGPUè®¾å¤‡")
    for i in range(total_gpus):
        gpu_name = torch.cuda.get_device_name(i)
        print(f"   GPU {i}: {gpu_name}")
    
    # ç¡®å®šå®é™…ä½¿ç”¨çš„GPUæ•°é‡
    if num_gpus_to_use is None:
        num_gpus = total_gpus
        print(f"\nâœ… ä½¿ç”¨æ‰€æœ‰ {num_gpus} ä¸ªGPU")
    else:
        num_gpus = min(num_gpus_to_use, total_gpus)
        if num_gpus_to_use > total_gpus:
            print(f"\nâš ï¸  è­¦å‘Š: è¯·æ±‚ä½¿ç”¨ {num_gpus_to_use} ä¸ªGPUï¼Œä½†åªæœ‰ {total_gpus} ä¸ªå¯ç”¨ï¼Œå°†ä½¿ç”¨ {num_gpus} ä¸ªGPU")
        else:
            print(f"\nâœ… ä½¿ç”¨æŒ‡å®šçš„ {num_gpus} ä¸ªGPU (GPU 0-{num_gpus-1})")
    
    # åŠ è½½æ•°æ®
    print(f"\nğŸ“– æ­£åœ¨åŠ è½½æ•°æ®: {input_file}")
    with open(input_file, 'r') as f:
        data = json.load(f)
    
    total_images = len(data)
    total_relations = sum(len(img['relations']) for img in data)
    print(f"   åŠ è½½äº† {total_images} å¼ å›¾ç‰‡ï¼Œå…± {total_relations} ä¸ªå…³ç³»")
    
    # å‡†å¤‡æ¨¡å‹å‚æ•°
    model_args = ModelArguments(
        model_name='/public/home/xiaojw2025/Workspace/VLM2Vec/models/qwen_vl/Qwen2-VL-2B-Instruct',
        # checkpoint_path='/public/home/xiaojw2025/Workspace/VLM2Vec/models/qwen_vl/Qwen2-VL-2B-Instruct',
        # checkpoint_path='/public/home/xiaojw2025/Workspace/VLM2Vec/models/VLM2Vec-Qwen2VL-2B',
        checkpoint_path='/public/home/xiaojw2025/Workspace/VLM2Vec/models/train_5k_ratio',
        pooling='last',
        normalize=True,
        model_backbone='qwen2_vl',
        lora=True
    )
    
    data_args = DataArguments(
        resize_min_pixels=56 * 56,
        resize_max_pixels=28 * 28 * 1280
    )
    
    # æ•°æ®åˆ†ç‰‡ï¼šå°†æ•°æ®å‡åŒ€åˆ†é…åˆ°å„ä¸ªGPU
    print(f"\nğŸ“Š æ•°æ®åˆ†ç‰‡: å°† {total_images} å¼ å›¾ç‰‡åˆ†é…åˆ° {num_gpus} ä¸ªGPU")
    data_shards = []
    images_per_gpu = math.ceil(total_images / num_gpus)
    for i in range(num_gpus):
        start_idx = i * images_per_gpu
        end_idx = min((i + 1) * images_per_gpu, total_images)
        shard = data[start_idx:end_idx]
        data_shards.append(shard)
        print(f"   GPU {i}: {len(shard)} å¼ å›¾ç‰‡ (ç´¢å¼• {start_idx}-{end_idx-1})")
    
    # ä½¿ç”¨å¤šè¿›ç¨‹è¿›è¡Œå¤šGPUå¹¶è¡Œæ¨ç†
    print(f"\nğŸš€ å¼€å§‹å¤šGPUå¹¶è¡Œæ¨ç†...\n")
    
    # åˆ›å»ºå…±äº«å­—å…¸å’Œé˜Ÿåˆ—
    manager = Manager()
    predicate_vectors_dict = manager.dict()  # å…±äº«çš„è°“è¯å‘é‡å­—å…¸
    result_queue = Queue()  # ç»“æœé˜Ÿåˆ—
    progress_queue = Queue()  # è¿›åº¦é˜Ÿåˆ—
    
    # å¯åŠ¨å¤šä¸ªè¿›ç¨‹
    processes = []
    for gpu_id in range(num_gpus):
        if len(data_shards[gpu_id]) > 0:  # åªå¯åŠ¨æœ‰æ•°æ®çš„GPUè¿›ç¨‹
            p = Process(
                target=process_data_shard,
                args=(gpu_id, data_shards[gpu_id], model_args, data_args, 
                      predicate_vectors_dict, result_queue, progress_queue)
            )
            p.start()
            processes.append(p)
            print(f"   âœ… å¯åŠ¨GPU {gpu_id}è¿›ç¨‹")
    
    # ç›‘æ§è¿›åº¦
    completed_gpus = set()
    progress_messages = {}
    
    def print_progress():
        """æ‰“å°è¿›åº¦ä¿¡æ¯"""
        while not progress_queue.empty():
            try:
                gpu_id, message = progress_queue.get_nowait()
                progress_messages[gpu_id] = message
            except:
                break
        
        # æ‰“å°æ‰€æœ‰GPUçš„è¿›åº¦
        for gpu_id in range(num_gpus):
            if gpu_id in progress_messages:
                print(f"   {progress_messages[gpu_id]}")
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆå¹¶æ”¶é›†ç»“æœ
    print("\nğŸ“ˆ æ¨ç†è¿›åº¦:")
    all_results = {}
    
    while len(completed_gpus) < len(processes):
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°ç»“æœ
        try:
            result = result_queue.get(timeout=1)
            if 'error' in result:
                print(f"\nâŒ {result['error']}")
                completed_gpus.add(result['gpu_id'])
            else:
                all_results[result['gpu_id']] = result
                completed_gpus.add(result['gpu_id'])
                print(f"   âœ… GPU {result['gpu_id']} å®Œæˆ")
        except:
            pass
        
        # æ‰“å°è¿›åº¦
        print_progress()
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ç»“æŸ
    for p in processes:
        p.join()
        p.terminate()
    
    print("\nâœ… æ‰€æœ‰GPUå¤„ç†å®Œæˆï¼Œæ­£åœ¨åˆå¹¶ç»“æœ...")
    
    # åˆå¹¶æ‰€æœ‰GPUçš„ç»“æœ
    per_image_candidates = {}
    all_relations_info = []
    
    # æŒ‰GPU IDé¡ºåºåˆå¹¶ç»“æœ
    for gpu_id in sorted(all_results.keys()):
        result = all_results[gpu_id]
        if 'error' in result:
            continue
        
        # åˆå¹¶æ¯å¼ å›¾ç‰‡çš„å€™é€‰
        for image_id, candidates in result['per_image_candidates'].items():
            per_image_candidates[image_id] = candidates
    
    # é‡æ–°åˆ†é…å…³ç³»ç´¢å¼•ï¼ˆåŸºäºåˆå¹¶åçš„æ•°æ®ï¼‰
    print("   é‡æ–°åˆ†é…å…³ç³»ç´¢å¼•...")
    global_relation_idx = 0
    
    # æŒ‰å›¾ç‰‡IDæ’åºå¤„ç†ï¼Œç¡®ä¿ä¸€è‡´æ€§
    for image_id in sorted(per_image_candidates.keys()):
        candidates = per_image_candidates[image_id]
        image_relation_idx = 0
        
        # æ”¶é›†è¯¥å›¾ç‰‡çš„æ‰€æœ‰GTå…³ç³»ï¼ˆå»é‡ï¼‰
        gt_relations_set = set()
        gt_relations_list = []
        for cand in candidates:
            if cand['has_gt'] and cand['gt_predicate']:
                key = (cand['subject'], cand['object'], cand['gt_predicate'])
                if key not in gt_relations_set:
                    gt_relations_set.add(key)
                    gt_relations_list.append({
                        'subject': cand['subject'],
                        'object': cand['object'],
                        'gt_predicate': cand['gt_predicate']
                    })
        
        # ä¸ºæ¯ä¸ªGTå…³ç³»åˆ†é…å…¨å±€ç´¢å¼•
        image_relation_idx_map = {}  # (subject, object, gt_predicate) -> relation_idx
        for rel_info in gt_relations_list:
            key = (rel_info['subject'], rel_info['object'], rel_info['gt_predicate'])
            image_relation_idx_map[key] = global_relation_idx
            
            all_relations_info.append({
                'relation_idx': global_relation_idx,
                'image_id': image_id,
                'image_relation_idx': image_relation_idx,
                'subject': rel_info['subject'],
                'object': rel_info['object'],
                'gt_predicate': rel_info['gt_predicate']
            })
            global_relation_idx += 1
            image_relation_idx += 1
        
        # æ›´æ–°å€™é€‰ä¸­çš„å…³ç³»ç´¢å¼•
        for cand in candidates:
            if cand['has_gt'] and cand['gt_predicate']:
                key = (cand['subject'], cand['object'], cand['gt_predicate'])
                if key in image_relation_idx_map:
                    rel_idx = image_relation_idx_map[key]
                    cand['relation_idx'] = rel_idx
                    cand['global_relation_idx'] = rel_idx
                else:
                    cand['relation_idx'] = -1
                    cand['global_relation_idx'] = -1
            else:
                cand['relation_idx'] = -1
                cand['global_relation_idx'] = -1
    
    # å¤šGPUæ¨¡å¼ä¸‹ï¼Œç»“æœå·²ç»åœ¨process_data_shardä¸­å¤„ç†å®Œæˆå¹¶åˆå¹¶
    # ç°åœ¨ç›´æ¥è¿›å…¥ç»“æœç»Ÿè®¡å’Œä¿å­˜é˜¶æ®µ
    
    print(f"\nâœ… é¢„æµ‹å®Œæˆï¼")
    print(f"   æ€»å›¾ç‰‡æ•°: {len(per_image_candidates)}")
    print(f"   æ€»GTå…³ç³»æ•°: {len(all_relations_info)}")
    total_candidates = sum(len(candidates) for candidates in per_image_candidates.values())
    print(f"   æ€»å€™é€‰é¢„æµ‹æ•°: {total_candidates}")
    
    # ç»Ÿè®¡é…å¯¹ä¿¡æ¯
    total_pairs = 0
    total_gt_pairs = 0
    for candidates in per_image_candidates.values():
        pairs_in_image = set((cand['subject'], cand['object']) for cand in candidates)
        gt_pairs_in_image = set((cand['subject'], cand['object']) for cand in candidates if cand['has_gt'])
        total_pairs += len(pairs_in_image)
        total_gt_pairs += len(gt_pairs_in_image)
    
    print(f"   æ€»é¢„æµ‹é…å¯¹å¯¹æ•°: {total_pairs}")
    print(f"   æœ‰GTçš„é…å¯¹å¯¹æ•°: {total_gt_pairs}")
    print(f"   æ— GTçš„é…å¯¹å¯¹æ•°: {total_pairs - total_gt_pairs}")
    
    # 5. è®¡ç®—Per-Image Recall@50å¹¶å–å¹³å‡
    print("\nğŸ“Š è®¡ç®—Per-Image Recall@50ï¼ˆæ¯å¼ å›¾ç‰‡ç‹¬ç«‹è®¡ç®—å†å¹³å‡ï¼‰...")
    recall_results = calculate_average_recall_at_k(per_image_candidates, k=50)
    
    # 5.1 è®¡ç®—Mean Recall@50ï¼ˆé’ˆå¯¹æ¯ä¸ªè°“è¯ç±»åˆ«ï¼‰
    print("\nğŸ“Š è®¡ç®—Mean Recall@50ï¼ˆé’ˆå¯¹æ‰€æœ‰è°“è¯ç±»åˆ«ï¼‰...")
    mean_recall_results = calculate_mean_recall_per_predicate(per_image_candidates, PREDICATES, k=50)
    
    print("\n" + "="*80)
    print("è¯„ä¼°ç»“æœ (Per-Image Recall@50)")
    print("="*80)
    print(f"å¹³å‡ Recall@{recall_results['k']}: {recall_results['avg_recall@k']:.4f} ({recall_results['avg_recall@k']*100:.2f}%)")
    print(f"æ€»å›¾ç‰‡æ•°: {recall_results['total_images']}")
    print(f"æ€»å¬å›å…³ç³»æ•°: {recall_results['total_recalled_relations']}/{recall_results['total_gt_relations']}")
    
    # è®¡ç®—å¹³å‡é…å¯¹ç»Ÿè®¡
    avg_total_pairs = sum(r.get('total_pairs', 0) for r in recall_results['per_image_results']) / len(recall_results['per_image_results'])
    avg_gt_pairs = sum(r.get('gt_pairs', 0) for r in recall_results['per_image_results']) / len(recall_results['per_image_results'])
    avg_non_gt_pairs = sum(r.get('non_gt_pairs', 0) for r in recall_results['per_image_results']) / len(recall_results['per_image_results'])
    
    print(f"å¹³å‡æ¯å¼ å›¾ç‰‡é¢„æµ‹é…å¯¹å¯¹æ•°: {avg_total_pairs:.1f}")
    print(f"å¹³å‡æ¯å¼ å›¾ç‰‡æœ‰GTçš„é…å¯¹å¯¹æ•°: {avg_gt_pairs:.1f}")
    print(f"å¹³å‡æ¯å¼ å›¾ç‰‡æ— GTçš„é…å¯¹å¯¹æ•°: {avg_non_gt_pairs:.1f}")
    
    if recall_results['images_with_insufficient_candidates'] > 0:
        print(f"å€™é€‰æ•°ä¸è¶³{recall_results['k']}çš„å›¾ç‰‡: {recall_results['images_with_insufficient_candidates']}/{recall_results['total_images']}")
    print("="*80)
    
    print("\n" + "="*80)
    print("è¯„ä¼°ç»“æœ (Mean Recall@50 - æ‰€æœ‰è°“è¯ç±»åˆ«)")
    print("="*80)
    print(f"Mean Recall@{mean_recall_results['k']}: {mean_recall_results['mean_recall@k']:.4f} ({mean_recall_results['mean_recall@k']*100:.2f}%)")
    print(f"æœ‰æ•ˆè°“è¯ç±»åˆ«æ•°: {mean_recall_results['num_valid_predicates']}/{mean_recall_results['total_predicates']}")
    print("="*80)
    
    # æ˜¾ç¤ºæ¯ä¸ªè°“è¯çš„recallï¼ˆå‰10ä¸ªå’Œå10ä¸ªï¼‰
    print("\nè°“è¯ç±»åˆ«Recallè¯¦æƒ…ï¼ˆæŒ‰recallæ’åºï¼‰:")
    sorted_predicates = sorted(
        mean_recall_results['per_predicate_recall'].items(),
        key=lambda x: x[1]['recall'],
        reverse=True
    )
    
    # åªæ˜¾ç¤ºæœ‰GTçš„è°“è¯
    predicates_with_gt = [(pred, stats) for pred, stats in sorted_predicates if stats['total'] > 0]
    
    if len(predicates_with_gt) > 0:
        print("\n  Top-10 è¡¨ç°æœ€å¥½çš„è°“è¯:")
        for i, (pred, stats) in enumerate(predicates_with_gt[:10], 1):
            print(f"    {i:2d}. {pred:20s}: R={stats['recall']:.4f} ({stats['hit']:3d}/{stats['total']:3d})")
        
        if len(predicates_with_gt) > 10:
            print("\n  Bottom-10 è¡¨ç°æœ€å·®çš„è°“è¯:")
            for i, (pred, stats) in enumerate(predicates_with_gt[-10:], 1):
                print(f"    {i:2d}. {pred:20s}: R={stats['recall']:.4f} ({stats['hit']:3d}/{stats['total']:3d})")
    
    # 6. æ˜¾ç¤ºæ¯å¼ å›¾ç‰‡çš„recallåˆ†å¸ƒ
    per_image_recalls = [r['recall@k'] for r in recall_results['per_image_results']]
    if per_image_recalls:
        print(f"\nRecallåˆ†å¸ƒç»Ÿè®¡:")
        print(f"  æœ€å¤§å€¼: {max(per_image_recalls):.4f}")
        print(f"  æœ€å°å€¼: {min(per_image_recalls):.4f}")
        print(f"  ä¸­ä½æ•°: {sorted(per_image_recalls)[len(per_image_recalls)//2]:.4f}")
    
    # 7. æ”¶é›†æ‰€æœ‰å€™é€‰ç”¨äºå±•ç¤ºï¼ˆå¯é€‰ï¼‰
    all_candidate_predictions = []
    for candidates in per_image_candidates.values():
        all_candidate_predictions.extend(candidates)
    
    candidates_sorted = sorted(all_candidate_predictions, key=lambda x: x['similarity'], reverse=True)
    top50_global_candidates = candidates_sorted[:100]
    
    # 7.1 ä¸ºæ¯å¼ å›¾ç‰‡æ”¶é›†Top-100å€™é€‰ç»“æœ
    print("\nğŸ“¦ æ­£åœ¨æ•´ç†æ¯å¼ å›¾ç‰‡çš„Top-100å€™é€‰ç»“æœ...")
    per_image_top100_candidates = {}
    total_top100_candidates = 0
    
    for image_id, candidates in per_image_candidates.items():
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        sorted_candidates = sorted(candidates, key=lambda x: x['similarity'], reverse=True)
        # å–Top-100
        top100 = sorted_candidates[:min(100, len(sorted_candidates))]
        per_image_top100_candidates[image_id] = top100
        total_top100_candidates += len(top100)
    
    print(f"   æ”¶é›†äº† {len(per_image_top100_candidates)} å¼ å›¾ç‰‡çš„Top-100å€™é€‰")
    print(f"   æ€»å€™é€‰æ•°: {total_top100_candidates}")
    
    # 8. ä¿å­˜ç»“æœ
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœåˆ°: {output_file}")
    output_data = {
        'summary': {
            'evaluation_method': 'per-image-all-pairs',
            'total_images': len(per_image_candidates),
            'total_gt_relations': len(all_relations_info),
            'total_candidates': total_candidates,
            'total_top100_candidates': total_top100_candidates,  # æ–°å¢ï¼šTop-100å€™é€‰æ€»æ•°
            'avg_recall@50': recall_results['avg_recall@k'],
            'mean_recall@50': mean_recall_results['mean_recall@k'],
            'total_recalled_relations': recall_results['total_recalled_relations'],
            'total_gt_relations': recall_results['total_gt_relations'],
            'num_valid_predicates': mean_recall_results['num_valid_predicates'],
            'images_with_insufficient_candidates': recall_results['images_with_insufficient_candidates'],
            # æ–°å¢é…å¯¹ç»Ÿè®¡
            'total_pairs': total_pairs,
            'total_gt_pairs': total_gt_pairs,
            'total_non_gt_pairs': total_pairs - total_gt_pairs,
            'avg_pairs_per_image': total_pairs / len(per_image_candidates) if len(per_image_candidates) > 0 else 0,
            'avg_gt_pairs_per_image': total_gt_pairs / len(per_image_candidates) if len(per_image_candidates) > 0 else 0
        },
        'per_image_results': recall_results['per_image_results'],
        'mean_recall_per_predicate': mean_recall_results['per_predicate_recall'],
        'all_relations': all_relations_info,
        'per_image_top100_candidates': per_image_top100_candidates,  # æ–°å¢ï¼šæ¯å¼ å›¾ç‰‡çš„Top-100å€™é€‰
        'top50_global_candidates': top50_global_candidates,  # å…¨å±€æ’åºçš„top50ï¼ˆå‚è€ƒç”¨ï¼‰
        # 'all_candidates': all_candidate_predictions  # å®Œæ•´çš„å€™é€‰åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¯èƒ½å¾ˆå¤§ï¼‰
    }
    
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print("âœ… ç»“æœå·²ä¿å­˜ï¼")
    
    # 9. æ˜¾ç¤ºä¸€äº›æ ·ä¾‹
    print("\n" + "="*80)
    print("Per-Image Recallæ ·ä¾‹ï¼ˆå‰5å¼ å›¾ç‰‡ï¼‰")
    print("="*80)
    for i, img_result in enumerate(recall_results['per_image_results'][:5], 1):
        print(f"\n{i}. å›¾ç‰‡#{img_result['image_id']}")
        print(f"   Recall@50: {img_result['recall@k']:.4f} ({img_result['recall@k']*100:.2f}%)")
        print(f"   å¬å›: {img_result['recalled_relations']}/{img_result['total_gt_relations']} å…³ç³»")
        actual_k_info = f" (å®é™…å–{img_result['actual_k']}ä¸ª)" if img_result['actual_k'] < img_result['k'] else ""
        print(f"   å€™é€‰æ•°: {img_result['total_candidates']} (Top-{img_result['k']}ä¸­å–{img_result['top_k_candidates']}ä¸ª{actual_k_info})")
        print(f"   é…å¯¹ç»Ÿè®¡: æ€»é…å¯¹{img_result.get('total_pairs', 0)}å¯¹, æœ‰GTé…å¯¹{img_result.get('gt_pairs', 0)}å¯¹, æ— GTé…å¯¹{img_result.get('non_gt_pairs', 0)}å¯¹")
    
    print("\n" + "="*80)
    print("å…¨å±€Top-50å€™é€‰é¢„æµ‹æ ·ä¾‹ï¼ˆå‰10ä¸ªï¼Œä»…ä¾›å‚è€ƒï¼‰")
    print("="*80)
    for i, pred in enumerate(top50_global_candidates[:10], 1):
        status = "âœ…" if pred['is_correct'] else "âŒ"
        print(f"\n{i}. {status} æ’å#{i} (ç›¸ä¼¼åº¦: {pred['similarity']:.4f})")
        print(f"   å›¾ç‰‡#{pred['image_id']}, å…³ç³»#{pred['relation_idx']}: {pred['subject']} --[{pred['predicted_predicate']}]--> {pred['object']}")
        print(f"   GTè°“è¯: {pred['gt_predicate']}")


if __name__ == "__main__":
    # è®¾ç½®multiprocessingå¯åŠ¨æ–¹æ³•ä¸º'spawn'ï¼Œä»¥æ”¯æŒCUDAå¤šè¿›ç¨‹
    # Linuxç³»ç»Ÿé»˜è®¤ä½¿ç”¨'fork'ï¼Œä½†CUDAä¸æ”¯æŒåœ¨forkçš„å­è¿›ç¨‹ä¸­é‡æ–°åˆå§‹åŒ–
    # å¿…é¡»åœ¨å¯¼å…¥multiprocessingåã€åˆ›å»ºä»»ä½•è¿›ç¨‹ä¹‹å‰è®¾ç½®
    try:
        import multiprocessing
        if multiprocessing.get_start_method(allow_none=True) != 'spawn':
            multiprocessing.set_start_method('spawn', force=True)
    except RuntimeError:
        # å¦‚æœå·²ç»è®¾ç½®è¿‡å¯åŠ¨æ–¹æ³•ï¼Œå¿½ç•¥é”™è¯¯
        pass
    
    main()

